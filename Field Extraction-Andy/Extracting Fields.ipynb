{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot run the event loop while another loop is running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-de26c071e833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cardamage2/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_done_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_run_until_complete_cb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_task\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cardamage2/lib/python3.7/asyncio/base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             raise RuntimeError(\n\u001b[0;32m--> 529\u001b[0;31m                 'Cannot run the event loop while another loop is running')\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_coroutine_origin_tracking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_debug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ident\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot run the event loop while another loop is running"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pdfrw\n",
    "import os\n",
    "import asyncio\n",
    "import base64\n",
    "from aiohttp import ClientSession\n",
    "\n",
    "google_vision_api_key = ('AIzaSyCujojNEZTGf4pak-5TKTnQRrEP5KO7JAk')\n",
    "google_vision_api = \"https://vision.googleapis.com/v1/images:annotate\"\n",
    "\n",
    "\n",
    "def adjust_gamma(image, gamma):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    " \n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def apply_brightness_contrast(input_img, brightness, contrast, gamma):\n",
    "    if brightness != 0:\n",
    "        if brightness > 0:\n",
    "            shadow = brightness\n",
    "            highlight = 255\n",
    "        else:\n",
    "            shadow = 0\n",
    "            highlight = 255 + brightness\n",
    "        alpha_b = (highlight - shadow)/255\n",
    "        gamma_b = shadow\n",
    "\n",
    "        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n",
    "    else:\n",
    "        buf = input_img.copy()\n",
    "\n",
    "    if contrast != 0:\n",
    "        f = 131*(contrast + 127)/(127*(131-contrast))\n",
    "        alpha_c = f\n",
    "        gamma_c = 127*(1-f)\n",
    "\n",
    "        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n",
    "        \n",
    "    gray = cv2.cvtColor(buf, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return adjust_gamma(gray,gamma)\n",
    "\n",
    "def adjustColor(path):\n",
    "    img_gray = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    cv2.imwrite(\"grayscaled.jpg\", img_gray)\n",
    "    \n",
    "    average = np.average(img_gray)\n",
    "    print (average)\n",
    "    \n",
    "    if (average > 199):\n",
    "        img_temp = cv2.imread(path)\n",
    "        img = apply_brightness_contrast(img_temp, -100, 130, 2)\n",
    "        return (img)\n",
    "        #cv2.imwrite(\"adjusted.jpg\", img)\n",
    "        \n",
    "    elif (average < 200 and average > 150):\n",
    "        img_temp = cv2.imread(path)\n",
    "        img = apply_brightness_contrast(img_temp, -50, 110, 2)\n",
    "        return (img)\n",
    "        #cv2.imwrite(\"adjusted.jpg\", img)\n",
    "        \n",
    "    elif (average < 151 and average > 110):\n",
    "        img_temp = cv2.imread(path)\n",
    "        img = apply_brightness_contrast(img_temp, -20, 90, 4)\n",
    "        return (img)\n",
    "        #cv2.imwrite(\"adjusted.jpg\", img)\n",
    "    elif (average < 111):\n",
    "        img_temp = cv2.imread(path)\n",
    "        img = apply_brightness_contrast(img_temp, 50, 80, 2)\n",
    "        return (img)\n",
    "        #cv2.imwrite(\"adjusted.jpg\",img)\n",
    "\n",
    "def scaleImg(img):\n",
    "    height, width = img.shape[:2]\n",
    "    new_width = 1275\n",
    "    new_height = 1675\n",
    "    # get scaling factor\n",
    "    scaling_factor_x = new_width / float(width)\n",
    "    scaling_factor_y = new_height / float(height)\n",
    "\n",
    "    # resize image\n",
    "    img = cv2.resize(img, None, fx=scaling_factor_x, fy=scaling_factor_y, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return img\n",
    "\n",
    "# inputs: pdf_path: path to the template pdf\n",
    "# inputs: img_paths: array of cv2 images for each page in the pdf (ordered)\n",
    "# inputs: skip_corners (optional): skips the automatic corner detection and just uses the full image if true\n",
    "# outputs: dict of bounding boxes see /csio-forms/oaf1.json for an example\n",
    "def getPdfBoxes(pdf_path, img_paths, skip_corners=False):\n",
    "    ANNOT_KEY = '/Annots'\n",
    "    ANNOT_FIELD_KEY = '/T'\n",
    "    ANNOT_VAL_KEY = '/V'\n",
    "    ANNOT_RECT_KEY = '/Rect'\n",
    "    SUBTYPE_KEY = '/Subtype'\n",
    "    WIDGET_SUBTYPE_KEY = '/Widget'\n",
    "    PARENT_KEY = '/Parent'\n",
    "    FIELD_TYPE_KEY = '/FT'\n",
    "    CHECKBOX_KEY = '/Btn'\n",
    "    BOX_KEY = '/Rect'\n",
    "    SIZE_KEY = '/Size'\n",
    "    \n",
    "    bounding_boxes = []\n",
    "\n",
    "    template_pdf = pdfrw.PdfReader(pdf_path)\n",
    "    template_pdf.Root.AcroForm.update(pdfrw.PdfDict(NeedAppearances=pdfrw.PdfObject('true')))\n",
    "\n",
    "    # IDK what this is think it's width\n",
    "\n",
    "    width = template_pdf.pages[0].MediaBox[2]\n",
    "    height = template_pdf.pages[0].MediaBox[3]\n",
    "\n",
    "    for i in range(len(template_pdf.pages)):\n",
    "        bounding_boxes.append({})\n",
    "        annotations = template_pdf.pages[i][ANNOT_KEY]\n",
    "\n",
    "        for annotation in annotations:\n",
    "            if annotation[SUBTYPE_KEY] == WIDGET_SUBTYPE_KEY:\n",
    "                if annotation[PARENT_KEY] and annotation[PARENT_KEY][ANNOT_FIELD_KEY]:\n",
    "                    if annotation[PARENT_KEY][ANNOT_FIELD_KEY][1:-1] not in bounding_boxes[i].keys():\n",
    "                        bounding_boxes[i][annotation[PARENT_KEY][ANNOT_FIELD_KEY][1:-1]] = []\n",
    "\n",
    "                    box = []\n",
    "\n",
    "                    type = 'checkbox' if annotation[PARENT_KEY][FIELD_TYPE_KEY] == CHECKBOX_KEY else 'text'\n",
    "                    \n",
    "                    for point in annotation[BOX_KEY]:\n",
    "                        index = (annotation[BOX_KEY].index(point))\n",
    "                        if (index == 0 or index == 2):\n",
    "                            box.append(float(point)/float(width))\n",
    "                        else:\n",
    "                            box.append(float(point)/float(height))\n",
    "\n",
    "                    bounding_boxes[i][annotation[PARENT_KEY][ANNOT_FIELD_KEY][1:-1]].append({'box': box, 'type': type})\n",
    "\n",
    "                if annotation[ANNOT_FIELD_KEY]:\n",
    "                    if annotation[ANNOT_FIELD_KEY][1:-1] not in bounding_boxes[i].keys():\n",
    "                        bounding_boxes[i][annotation[ANNOT_FIELD_KEY][1:-1]] = []\n",
    "\n",
    "                    box = []\n",
    "\n",
    "                    type = 'checkbox' if annotation[FIELD_TYPE_KEY] == CHECKBOX_KEY else 'text'\n",
    "    \n",
    "                    for point in annotation[BOX_KEY]:\n",
    "                        index = (annotation[BOX_KEY].index(point))\n",
    "                        if (index == 0 or index == 2):\n",
    "                            box.append(float(point)/float(width))\n",
    "                        else:\n",
    "                            box.append(float(point)/float(height))\n",
    "\n",
    "                    bounding_boxes[i][annotation[ANNOT_FIELD_KEY][1:-1]].append({'box': box, 'type': type})\n",
    "\n",
    "    \n",
    "    for i in range(len(img_paths)):\n",
    "        form = cv2.imread(img_paths[i])\n",
    "        width = len(form[0])\n",
    "        height = len(form)\n",
    "        print (width)\n",
    "        print(height)\n",
    "        for key in bounding_boxes[i].keys():\n",
    "            for j, box in enumerate(bounding_boxes[i][key]):\n",
    "                if key == 'Reset':\n",
    "                    continue\n",
    "\n",
    "                left_x = box['box'][0] * (width) - 10\n",
    "                right_x = box['box'][2]  * (width) + 10\n",
    "                top_y = height - box['box'][1] * (height + 60) + 40\n",
    "                bot_y = height - box['box'][3]  * (height + 60) + 25\n",
    "\n",
    "                bounding_boxes[i][key][j]['box'] = [left_x, bot_y, right_x, top_y]\n",
    "    print(bounding_boxes)\n",
    "    form = scaleImg(cv2.imread(img_paths[1]))\n",
    "\n",
    "    for key in bounding_boxes[0]:\n",
    "        for box in bounding_boxes[0][key]:\n",
    "            if key == 'Reset':\n",
    "                continue\n",
    "            cv2.rectangle(form, (int(box['box'][0]), int(box['box'][3] )),\n",
    "                        (int(box['box'][2] ), int(box['box'][1] )), (100, 166, 189), 3)\n",
    "\n",
    "    cv2.imwrite(\"boundingBoxes.jpg\", form)\n",
    "    return bounding_boxes\n",
    "\n",
    "\n",
    "# calls google ocr to get the handwritten text from a field in the form\n",
    "# inputs: cv2 image of the field\n",
    "# outputs: {'text': text in the field, 'confidence': confidence score}\n",
    "async def getRegionText(img):\n",
    "    try:\n",
    "        retval, buffer = cv2.imencode('.jpg', img)\n",
    "    except:\n",
    "        return {'text': '', 'confidence': -1}\n",
    "\n",
    "    image64 = base64.b64encode(buffer)\n",
    "\n",
    "    params = {'key': google_vision_api_key}\n",
    "    body = {\"requests\":[{\"imageContext\": {'languageHints' : ['en-t-i0-handwrit']}, \"image\":{\"content\": str(image64)[2:-1]},\"features\":[{\"type\":\"DOCUMENT_TEXT_DETECTION\",\"maxResults\":1}]}]}\n",
    "\n",
    "    async with ClientSession() as session:\n",
    "        async with session.post(google_vision_api, params=params, json=body) as resp:\n",
    "            resp = await resp.json()\n",
    "            try:\n",
    "                text = resp['responses'][0]['fullTextAnnotation']['text']\n",
    "            except:\n",
    "                text = ''\n",
    "\n",
    "            try:\n",
    "                confidence = resp['responses'][0]['fullTextAnnotation']['pages'][0]['blocks'][0]['confidence']\n",
    "            except:\n",
    "                confidence = -1\n",
    "\n",
    "            return {'text': ' '.join(text.split('\\n')), 'confidence': confidence}\n",
    "\n",
    "\n",
    "# gets the text for all regions in a form page\n",
    "# inputs: form: cv2 image of the form page\n",
    "# inputs: regions: dict of bounding boxes for each field on the page\n",
    "# inputs: auto_mode (optional): uses the automatic bounding boxes instead of the manual ones\n",
    "# outputs: [keys of fields, values in fields, confidence of field]\n",
    "async def callGoogle(form, regions, auto_mode=False):\n",
    "    width = len(form[0])\n",
    "    height = len(form)\n",
    "    keys = []\n",
    "    tasks = []\n",
    "    if auto_mode:\n",
    "        for key in regions.keys():\n",
    "            for box in regions[key]:\n",
    "                if box['type'] == 'text':\n",
    "                    crop_img = form[int(box['box'][1]):int(box['box'][3]),\n",
    "                               int(box['box'][0]):int(box['box'][2])]\n",
    "                    res = asyncio.ensure_future(getRegionText(crop_img))\n",
    "                    keys.append(key)\n",
    "                    tasks.append(res)\n",
    "    else:\n",
    "        for key in regions.keys():\n",
    "            for box in regions[key]:\n",
    "                if box['type'] == 'text':\n",
    "                    crop_img = form[int(box['box'][1]):int(box['box'][3]),\n",
    "                               int(box['box'][0]):int(box['box'][2])]\n",
    "                    res = asyncio.ensure_future(getRegionText(crop_img))\n",
    "                    keys.append(key)\n",
    "                    tasks.append(res)\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    # print(tasks)\n",
    "    print(results)\n",
    "\n",
    "    return [keys, results]\n",
    "\n",
    "\n",
    "async def test():\n",
    "    dirpath = os.getcwd()\n",
    "    fieldBounds = getPdfBoxes('AL.pdf', ['oafpbm/' + i for i in os.listdir( dirpath + '/oafpbm/') if i[len(i)-4:] == '.jpg'], skip_corners=True)\n",
    "    form = adjustColor('./oafpbm/1.jpg')\n",
    "    form = scaleImg(form)\n",
    "    regions = fieldBounds[0]\n",
    "    count  = 0\n",
    "    for key in regions.keys():\n",
    "        for box in regions[key]:\n",
    "            print(str(box['box']))\n",
    "            if box['type'] == 'text':\n",
    "                crop_img = form[int(box['box'][1]):int(box['box'][3]),\n",
    "                            int(box['box'][0]):int(box['box'][2])]\n",
    "                cv2.imwrite('./Cropped/' + str(count) + '.jpg', crop_img)\n",
    "                count+= 1\n",
    "\n",
    "    img1 = adjustColor('./oafpbm/1.jpg')\n",
    "    img1 = scaleImg(img1)\n",
    "    future1 = await callGoogle(img1, fieldBounds[0])\n",
    "    print(future1)\n",
    "\n",
    "loop = asyncio.new_event_loop()\n",
    "loop.run_until_complete(test())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
